{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0fa59f-7f43-4140-ba46-8cc66ee70c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056f904e-f6a3-4027-917f-55f58088fbd7",
   "metadata": {},
   "source": [
    "Load and preprocess dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731c5904-417e-41bc-abd9-0d97c920243c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist(binary_classification=True):\n",
    "    transform = transforms.Compose([transforms.ToTensor(), transforms.Lambda(lambda x: x.view(-1))])\n",
    "    train = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "    test = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "    if binary_classification:\n",
    "        train = [(x, float(y == 0)) for x, y in train]\n",
    "        test = [(x, float(y == 0)) for x, y in test]\n",
    "\n",
    "    train_loader = DataLoader(train, batch_size=64, shuffle=True)\n",
    "    test_loader = DataLoader(test, batch_size=64, shuffle=False)\n",
    "    return train_loader, test_loader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f5dac3-686f-405e-b391-37b8b2f086a6",
   "metadata": {},
   "source": [
    "Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2412aaaf-c8f4-445a-9532-afc381fdd2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegressionModel:\n",
    "    def __init__(self, input_dim):\n",
    "        self.w = np.zeros((input_dim, 1))\n",
    "        self.b = 0\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.sigmoid(X @ self.w + self.b)\n",
    "\n",
    "    def loss(self, X, y):\n",
    "        m = len(y)\n",
    "        preds = self.predict(X)\n",
    "        loss = -np.mean(y * np.log(preds + 1e-8) + (1 - y) * np.log(1 - preds + 1e-8))\n",
    "        return loss\n",
    "\n",
    "    def gradient(self, X, y):\n",
    "        m = len(y)\n",
    "        preds = self.predict(X)\n",
    "        error = preds - y\n",
    "        dw = (X.T @ error) / m\n",
    "        db = np.mean(error)\n",
    "        return dw, db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea185f5-1918-4c62-9861-fb0c0a4fe9ad",
   "metadata": {},
   "source": [
    " SGD Optimizer (Student: extend this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84e3099-022e-403e-b7f9-427eb212e2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd_train(model, train_loader, lr=0.01, num_epochs=10):\n",
    "    loss_history = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for batch in train_loader:\n",
    "            x_batch, y_batch = batch\n",
    "            X = x_batch.numpy()\n",
    "            y = y_batch.numpy().reshape(-1, 1)\n",
    "\n",
    "            dw, db = model.gradient(X, y)\n",
    "            model.w -= lr * dw\n",
    "            model.b -= lr * db\n",
    "\n",
    "            loss = model.loss(X, y)\n",
    "            loss_history.append(loss)\n",
    "\n",
    "    return loss_history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8646faf-7c72-4a82-b993-7cdac09e30bf",
   "metadata": {},
   "source": [
    "Plotting and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63d9cb8-ed35-41b6-a877-790876a68830",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(losses, label='SGD'):\n",
    "    plt.plot(losses, label=label)\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Loss vs Iteration\")\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb6c826-c0d6-4ccd-ad05-dc329d77f04c",
   "metadata": {},
   "source": [
    " Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed73145c-b25c-4edb-a84b-379614c55178",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    train_loader, test_loader = load_mnist()\n",
    "    input_dim = 28 * 28\n",
    "    model = LogisticRegressionModel(input_dim=input_dim)\n",
    "\n",
    "    # SGD example\n",
    "    loss_sgd = sgd_train(model, train_loader, lr=0.1, num_epochs=5)\n",
    "    plot_loss(loss_sgd, label='SGD (lr=0.1)')\n",
    "\n",
    "    # Students: Add momentum, Adam, and compare\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
